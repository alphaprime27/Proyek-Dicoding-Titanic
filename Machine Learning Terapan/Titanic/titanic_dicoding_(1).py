# -*- coding: utf-8 -*-
"""titanic-dicoding (1).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1J7jIgyEf6OsxKPSJYm1VblME-Cb6tf8i

# Titanic Machine Learning

<img src= "https://www.historic-uk.com/wp-content/uploads/2017/04/the-sinking-of-the-rms-titanic.jpg" alt ="Titanic" style='width: 600px;'>

___
## Importing Libraries and Dataset

Pada cell code di bawah ini, saya mengimpor berbagai libraries.
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
# %matplotlib inline
import seaborn as sns
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
from sklearn.model_selection import train_test_split
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import OrdinalEncoder
from sklearn.metrics import mean_squared_error

import os
for dirname, _, filenames in os.walk('/kaggle/input'):
    for filename in filenames:
        print(os.path.join(dirname, filename))

"""Pada cell code di bawah ini, saya mengimpor dataset."""

data_train = pd.read_csv("/kaggle/input/titanic/train.csv")
data_test = pd.read_csv("/kaggle/input/titanic/test.csv")
data_train.head()

"""Pada cell code di bawah ini, saya melihat rangkuman dari dataset."""

data_train.describe()

"""Pada cell code di bawah ini, saya melakukan cek pada NaN values di dalam dataset"""

sns.heatmap(data_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')

"""Pada cell code di bawah ini, saya drop cabin karena banyak sekali NaN valuesnya, dan pada kolom age sama isi value - value yang Nan dengan nilai median"""

data_train.drop(['Cabin'],axis=1,inplace=True)
data_train['Age'] = data_train['Age'].fillna((data_train['Age'].median()))

"""Pada cell code di bawah ini, saya melakukan cek dan ternyata sudah tidak ada NaN values"""

sns.heatmap(data_train.isnull(),yticklabels=False,cbar=False,cmap='viridis')

"""Pada cell code di bawah ini, saya menghilangkan value - value yang terlalu jauh"""

Q1 = data_train.quantile(0.25)
Q3 = data_train.quantile(0.75)
IQR=Q3-Q1
data_train=data_train[~((data_train<(Q1-1.5*IQR))|(data_train>(Q3+1.5*IQR))).any(axis=1)]

"""___
## Univariate Analysis

Pada cell code di bawah ini, saya membagi num dengan object kolom
"""

train_num = ['Age','SibSp','Fare']
train_cat = ['Survived','Pclass','Sex','Ticket','Embarked']

"""Pada cell code di bawah ini, saya melakukan univariate eda pada kolom - kolom object"""

for i in range(len(train_cat)):
    feature = train_cat[i]
    count = data_train[feature].value_counts()
    percent = 100*data_train[feature].value_counts(normalize=True)
    df = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(1)})
    print(df)
    count.plot(kind='bar', title=feature)
    plt.show()

"""___
## Multivariate Analysis

Pada cell code di bawah ini, saya melakukan cek pada Multivariate EDA dengan heatmap
"""

plt.figure(figsize=(10, 8))
correlation_matrix = data_train.corr().round(2)

sns.heatmap(data=correlation_matrix, annot=True,linewidths=0.5 )
plt.title("Correlation Matrix", size=20)

"""Pada cell code di bawah ini, saya drop Pclass dan Parch karena rendahnya korelasi terhadap Survivability"""

data_train.drop(['Pclass','Parch'],axis=1,inplace=True)
data_train.head()

"""___
## Data Preparation

Pada cell code di bawah ini, saya melakukan get_dummies pada kolom sex dan embark
"""

sex = pd.get_dummies(data_train['Sex'])
embark = pd.get_dummies(data_train['Embarked'])

"""Pada cell code di bawah ini, saya drop 5 kolom yang tidak relevan dan meng-concat get_dummies dari sex dan embark sebelumnya"""

data_train.drop(['PassengerId','Sex','Embarked','Name','Ticket'],axis=1,inplace=True)
data_train = pd.concat([data_train,sex,embark],axis=1)
data_train.head()

"""Pada cell code di bawah ini, saya men-split dataset menjadi train dan validation"""

from sklearn.model_selection import train_test_split
 
X = data_train.drop(["Survived"],axis =1)
y = data_train["Survived"]
X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.2, random_state = 0)

"""Pada cell code di bawah ini, saya melakukan standardscaler pada x train dan x valid"""

from sklearn.preprocessing import StandardScaler
train_num = ['Age','SibSp','Fare']
scaler = StandardScaler()
scaler.fit(X_train[train_num])
scaler.fit(X_valid[train_num])
X_train[train_num] = scaler.transform(X_train.loc[:, train_num])
X_valid[train_num] = scaler.transform(X_valid.loc[:, train_num])
X_train.head()

"""___
## Model Development

Pada cell code di bawah ini, saya melakukan import pada beberapa model
"""

from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression

"""___
### Logistic Regressor

Pada cell code di bawah ini saya membuat satu model Logistic Regression dengan nama log dan melatihnya dengan data X_train dan y_train
"""

log=LogisticRegression()
log.fit(X_train,y_train)

"""Pada cell code di bawah ini saya melakukan prediksi pada X_valid"""

preds_LogisticRegression=log.predict(X_valid)

"""Pada cell code di bawah ini, saya mengkalkulasi akurasi, presisi, recall, dan F1 score pada model Logistic Regression"""

from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score
accuracy_LogisticRegression=accuracy_score(y_valid,preds_LogisticRegression)
print("LogisticRegression accuracy value: {:.2f}".format(accuracy_LogisticRegression))
print('LogisticRegression Precision: %.3f' % precision_score(y_valid,preds_LogisticRegression))
print('LogisticRegression Recall: %.3f' % recall_score(y_valid,preds_LogisticRegression))
print('LogisticRegression F1 Score: %.3f' % f1_score(y_valid,preds_LogisticRegression))

"""___
### XGBClassifier

Pada cell code di bawah ini, saya define parameter untuk xgbclassifier
"""

model_XGBClassifier = XGBClassifier()
model_XGBClassifier.fit(X_train, y_train,
          verbose=False)

preds_XGBClassifier = model_XGBClassifier.predict(X_valid)

"""Pada cell code di bawah ini, saya mengkalkulasi akurasi, presisi, recall, dan F1 score pada model xgbclassifier"""

accuracy_XGBClassifier=accuracy_score(y_valid,preds_XGBClassifier)
print("XGBClassifier accuracy value: {:.2f}".format(accuracy_XGBClassifier))
print('XGBClassifier Precision: %.3f' % precision_score(y_valid,preds_XGBClassifier))
print('XGBClassifier Recall: %.3f' % recall_score(y_valid,preds_XGBClassifier))
print('XGBClassifier F1 Score: %.3f' % f1_score(y_valid,preds_XGBClassifier))

"""___
## Choosing the best Model

Pada cell code di bawah ini, saya menggabungkan semua akurasi, presisi, recall, dan F1 pada semua model yang ada
"""

model = pd.DataFrame({'Logistic Regression': [accuracy_LogisticRegression,precision_score(y_valid,preds_LogisticRegression),recall_score(y_valid,preds_LogisticRegression),f1_score(y_valid,preds_LogisticRegression)],
                     'XGBClassifier': [accuracy_XGBClassifier,precision_score(y_valid,preds_XGBClassifier),recall_score(y_valid,preds_XGBClassifier),f1_score(y_valid,preds_XGBClassifier)],
                     },
              
             index=['Accuracy','Precision','Recall','F1'])
model

"""Ternyata XGBClassifier memiliki evaluasi metrik paling baik

___
# Preprocessing Test Data

Pada cell code di bawah ini, saya drop kolom - kolom yang juga sudah saya drop pada data train
"""

X_test=data_test.drop(['Cabin','Parch','PassengerId','Name','Ticket','Pclass'],axis =1)
test_num = ['Age','SibSp','Fare']
scaler = StandardScaler()
scaler.fit(X_test[train_num])
X_test[train_num] = scaler.transform(X_test.loc[:, test_num])

"""Pada cell code di bawah ini, saya melakukan get_dummies pada kolom sex dan embark yang kemudian juga di concat pada dataframe test"""

sex = pd.get_dummies(X_test['Sex'])
embark = pd.get_dummies(X_test['Embarked'])
X_test=X_test.drop(['Sex','Embarked'],axis =1)
X_test = pd.concat([X_test,sex,embark],axis=1)

X_test.head()

"""Pada cell code di bawah ini, saya memprediksi dari dataset test dengan model XGBClassifier karena XGBClassifier merupakan model yang terbaik"""

predictions=model_XGBClassifier.predict(X_test)

"""Pada cell code di bawah ini, saya menggabungkan id dan hasil prediksi pada semua dataframe baru untuk submission"""

output = pd.DataFrame({'PassengerId': data_test.PassengerId,
                       'Survived': predictions})
output.to_csv('submission.csv', index=False)
output.head()

